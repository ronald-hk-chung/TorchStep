
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../how-to-guides/">
      
      
        <link rel="next" href="../explanation/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.14">
    
    
      
        <title>Reference - Self-Study-Torch (sstorch) Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.10ba22f1.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#src.sstorch.learner.main_handler" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Self-Study-Torch (sstorch) Documentation" class="md-header__button md-logo" aria-label="Self-Study-Torch (sstorch) Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Self-Study-Torch (sstorch) Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Reference
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Self-Study-Torch (sstorch) Documentation" class="md-nav__button md-logo" aria-label="Self-Study-Torch (sstorch) Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Self-Study-Torch (sstorch) Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../how-to-guides/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How-To Guides
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Reference
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Reference
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler" class="md-nav__link">
    <span class="md-ellipsis">
      main_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner" class="md-nav__link">
    <span class="md-ellipsis">
      SSTLearner
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SSTLearner">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.freeze" class="md-nav__link">
    <span class="md-ellipsis">
      freeze
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.set_train_mode" class="md-nav__link">
    <span class="md-ellipsis">
      set_train_mode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.set_valid_mode" class="md-nav__link">
    <span class="md-ellipsis">
      set_valid_mode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.train_step" class="md-nav__link">
    <span class="md-ellipsis">
      train_step
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.unfreeze" class="md-nav__link">
    <span class="md-ellipsis">
      unfreeze
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.valid_step" class="md-nav__link">
    <span class="md-ellipsis">
      valid_step
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.callback_handler" class="md-nav__link">
    <span class="md-ellipsis">
      callback_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.callback_handler.Callback" class="md-nav__link">
    <span class="md-ellipsis">
      Callback
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.checkpoint_handler" class="md-nav__link">
    <span class="md-ellipsis">
      checkpoint_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.checkpoint_handler.CheckPointHandler" class="md-nav__link">
    <span class="md-ellipsis">
      CheckPointHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CheckPointHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.checkpoint_handler.CheckPointHandler.load_checkpoint" class="md-nav__link">
    <span class="md-ellipsis">
      load_checkpoint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.checkpoint_handler.CheckPointHandler.save_checkpoint" class="md-nav__link">
    <span class="md-ellipsis">
      save_checkpoint
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.device_handler" class="md-nav__link">
    <span class="md-ellipsis">
      device_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.device_handler.DeviceHandler" class="md-nav__link">
    <span class="md-ellipsis">
      DeviceHandler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.device_handler.to_device" class="md-nav__link">
    <span class="md-ellipsis">
      to_device
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler" class="md-nav__link">
    <span class="md-ellipsis">
      gradient_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler" class="md-nav__link">
    <span class="md-ellipsis">
      GradientHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GradientHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler.remove_clip" class="md-nav__link">
    <span class="md-ellipsis">
      remove_clip
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler.set_clip_backprop" class="md-nav__link">
    <span class="md-ellipsis">
      set_clip_backprop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler.set_clip_grad_norm" class="md-nav__link">
    <span class="md-ellipsis">
      set_clip_grad_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler.set_clip_grad_value" class="md-nav__link">
    <span class="md-ellipsis">
      set_clip_grad_value
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler" class="md-nav__link">
    <span class="md-ellipsis">
      hook_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler.HookHandler" class="md-nav__link">
    <span class="md-ellipsis">
      HookHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HookHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler.HookHandler.attach_backward_hooks" class="md-nav__link">
    <span class="md-ellipsis">
      attach_backward_hooks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler.HookHandler.attach_forward_hooks" class="md-nav__link">
    <span class="md-ellipsis">
      attach_forward_hooks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler.HookHandler.remove_hooks" class="md-nav__link">
    <span class="md-ellipsis">
      remove_hooks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler" class="md-nav__link">
    <span class="md-ellipsis">
      optimizer_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler" class="md-nav__link">
    <span class="md-ellipsis">
      OptimizerHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OptimizerHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.configure_optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      configure_optimizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.fit_one_cycle" class="md-nav__link">
    <span class="md-ellipsis">
      fit_one_cycle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.lr_range_test" class="md-nav__link">
    <span class="md-ellipsis">
      lr_range_test
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.make_lr_fn" class="md-nav__link">
    <span class="md-ellipsis">
      make_lr_fn
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.set_lr" class="md-nav__link">
    <span class="md-ellipsis">
      set_lr
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.set_lr_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      set_lr_scheduler
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.set_optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      set_optimizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.result_handler" class="md-nav__link">
    <span class="md-ellipsis">
      result_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.result_handler.ResultHandler" class="md-nav__link">
    <span class="md-ellipsis">
      ResultHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ResultHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.result_handler.ResultHandler.plot_loss_curve" class="md-nav__link">
    <span class="md-ellipsis">
      plot_loss_curve
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.tensorboard_handler" class="md-nav__link">
    <span class="md-ellipsis">
      tensorboard_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.tensorboard_handler.TBHandler" class="md-nav__link">
    <span class="md-ellipsis">
      TBHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TBHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.tensorboard_handler.TBHandler.add_graph" class="md-nav__link">
    <span class="md-ellipsis">
      add_graph
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.tensorboard_handler.TBHandler.set_tensorboard" class="md-nav__link">
    <span class="md-ellipsis">
      set_tensorboard
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.torchinfo_handler" class="md-nav__link">
    <span class="md-ellipsis">
      torchinfo_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.torchinfo_handler.TorchInfoHandler" class="md-nav__link">
    <span class="md-ellipsis">
      TorchInfoHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TorchInfoHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.torchinfo_handler.TorchInfoHandler.model_info" class="md-nav__link">
    <span class="md-ellipsis">
      model_info
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.utils" class="md-nav__link">
    <span class="md-ellipsis">
      utils
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.utils.set_seed" class="md-nav__link">
    <span class="md-ellipsis">
      set_seed
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../explanation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Explanation
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler" class="md-nav__link">
    <span class="md-ellipsis">
      main_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner" class="md-nav__link">
    <span class="md-ellipsis">
      SSTLearner
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SSTLearner">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.freeze" class="md-nav__link">
    <span class="md-ellipsis">
      freeze
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.set_train_mode" class="md-nav__link">
    <span class="md-ellipsis">
      set_train_mode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.set_valid_mode" class="md-nav__link">
    <span class="md-ellipsis">
      set_valid_mode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.train_step" class="md-nav__link">
    <span class="md-ellipsis">
      train_step
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.unfreeze" class="md-nav__link">
    <span class="md-ellipsis">
      unfreeze
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.main_handler.SSTLearner.valid_step" class="md-nav__link">
    <span class="md-ellipsis">
      valid_step
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.callback_handler" class="md-nav__link">
    <span class="md-ellipsis">
      callback_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.callback_handler.Callback" class="md-nav__link">
    <span class="md-ellipsis">
      Callback
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.checkpoint_handler" class="md-nav__link">
    <span class="md-ellipsis">
      checkpoint_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.checkpoint_handler.CheckPointHandler" class="md-nav__link">
    <span class="md-ellipsis">
      CheckPointHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CheckPointHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.checkpoint_handler.CheckPointHandler.load_checkpoint" class="md-nav__link">
    <span class="md-ellipsis">
      load_checkpoint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.checkpoint_handler.CheckPointHandler.save_checkpoint" class="md-nav__link">
    <span class="md-ellipsis">
      save_checkpoint
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.device_handler" class="md-nav__link">
    <span class="md-ellipsis">
      device_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.device_handler.DeviceHandler" class="md-nav__link">
    <span class="md-ellipsis">
      DeviceHandler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.device_handler.to_device" class="md-nav__link">
    <span class="md-ellipsis">
      to_device
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler" class="md-nav__link">
    <span class="md-ellipsis">
      gradient_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler" class="md-nav__link">
    <span class="md-ellipsis">
      GradientHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GradientHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler.remove_clip" class="md-nav__link">
    <span class="md-ellipsis">
      remove_clip
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler.set_clip_backprop" class="md-nav__link">
    <span class="md-ellipsis">
      set_clip_backprop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler.set_clip_grad_norm" class="md-nav__link">
    <span class="md-ellipsis">
      set_clip_grad_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.gradient_handler.GradientHandler.set_clip_grad_value" class="md-nav__link">
    <span class="md-ellipsis">
      set_clip_grad_value
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler" class="md-nav__link">
    <span class="md-ellipsis">
      hook_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler.HookHandler" class="md-nav__link">
    <span class="md-ellipsis">
      HookHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HookHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler.HookHandler.attach_backward_hooks" class="md-nav__link">
    <span class="md-ellipsis">
      attach_backward_hooks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler.HookHandler.attach_forward_hooks" class="md-nav__link">
    <span class="md-ellipsis">
      attach_forward_hooks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.hook_handler.HookHandler.remove_hooks" class="md-nav__link">
    <span class="md-ellipsis">
      remove_hooks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler" class="md-nav__link">
    <span class="md-ellipsis">
      optimizer_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler" class="md-nav__link">
    <span class="md-ellipsis">
      OptimizerHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OptimizerHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.configure_optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      configure_optimizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.fit_one_cycle" class="md-nav__link">
    <span class="md-ellipsis">
      fit_one_cycle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.lr_range_test" class="md-nav__link">
    <span class="md-ellipsis">
      lr_range_test
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.make_lr_fn" class="md-nav__link">
    <span class="md-ellipsis">
      make_lr_fn
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.set_lr" class="md-nav__link">
    <span class="md-ellipsis">
      set_lr
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.set_lr_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      set_lr_scheduler
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.optimizer_handler.OptimizerHandler.set_optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      set_optimizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.result_handler" class="md-nav__link">
    <span class="md-ellipsis">
      result_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.result_handler.ResultHandler" class="md-nav__link">
    <span class="md-ellipsis">
      ResultHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ResultHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.result_handler.ResultHandler.plot_loss_curve" class="md-nav__link">
    <span class="md-ellipsis">
      plot_loss_curve
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.tensorboard_handler" class="md-nav__link">
    <span class="md-ellipsis">
      tensorboard_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.tensorboard_handler.TBHandler" class="md-nav__link">
    <span class="md-ellipsis">
      TBHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TBHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.tensorboard_handler.TBHandler.add_graph" class="md-nav__link">
    <span class="md-ellipsis">
      add_graph
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.tensorboard_handler.TBHandler.set_tensorboard" class="md-nav__link">
    <span class="md-ellipsis">
      set_tensorboard
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.torchinfo_handler" class="md-nav__link">
    <span class="md-ellipsis">
      torchinfo_handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.torchinfo_handler.TorchInfoHandler" class="md-nav__link">
    <span class="md-ellipsis">
      TorchInfoHandler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TorchInfoHandler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.sstorch.learner.torchinfo_handler.TorchInfoHandler.model_info" class="md-nav__link">
    <span class="md-ellipsis">
      model_info
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.utils" class="md-nav__link">
    <span class="md-ellipsis">
      utils
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.sstorch.learner.utils.set_seed" class="md-nav__link">
    <span class="md-ellipsis">
      set_seed
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Reference</h1>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.main_handler"></a>
  <div class="doc doc-contents first">
  
      <p><code>SSTLearner</code> inherits from several sub-class handler to handler specific functions.</p>
<p>Below are the list of handlers:</p>
<p><code>DeviceHandler</code>     -   Device management, uses <code>torch.device('cuda')</code> if gpu available
<code>OptimizerHandler</code>  -   Set Optimizer and Learning rate scheduler
<code>TBHandler</code>         -   Set tensorboard for training monitor
<code>TorchInfoHandler</code>  -   Method to utilise torchinfo to show model summary
<code>ResultHandler</code>     -   Record training results within SSTLearner
<code>GradientHandler</code>   -   Gradient clipping
<code>HookHandler</code>       -   Adding forward and backward hook for PyTorch training
<code>CheckPointHandler</code> -   Saving and Loading of training checkpoint
<code>CBHandler</code>         -   Adding <code>Callback</code> for default and custom functions during training</p>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.main_handler.SSTLearner" class="doc doc-heading">
          <code>SSTLearner</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code>*<span title="src.sstorch.learner.main_handler.Handles">Handles</span></code></p>

  
      <p>SSTLearner contains pytorch training framework with utility functions</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SSTLearner</span><span class="p">(</span><span class="o">*</span><span class="n">Handles</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SSTLearner contains pytorch training framework with utility functions&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">metric_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">valid_dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the SSTLearner instance</span>

<span class="sd">        Args:</span>
<span class="sd">            model (nn.Module): torch model</span>
<span class="sd">            loss_fn (Callable): loss function</span>
<span class="sd">            metric_fn (Callable): metric function, Default to None</span>
<span class="sd">            train_dataloader (DataLoader): train dataloader, Default to None, can be set using set_loaders()</span>
<span class="sd">            valid_dataloader (DataLoader): valid dataloader, Default to None, can be set using set_loaders()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span> <span class="o">=</span> <span class="n">metric_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">train_dataloader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">valid_dataloader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="n">Handles</span><span class="p">:</span>
            <span class="n">handle</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method for SSTLearner to run train and valid loops</span>

<span class="sd">        Args:</span>
<span class="sd">            epochs (int): num of epochs to run</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_loop</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_dataloader</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_valid_loop</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_train_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_train_mode</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">for</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_num</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_loss_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_loss_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_valid_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_valid_mode</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_valid_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_metric</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
            <span class="k">for</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_num</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_dataloader</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_valid_loss_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_step</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_valid_loss_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_valid_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Standard train step&quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_batch</span><span class="p">()</span>
        <span class="n">y_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span><span class="p">(</span><span class="n">y_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">metric</span>

    <span class="k">def</span> <span class="nf">valid_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Standard valid step&quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_batch</span><span class="p">()</span>
        <span class="n">y_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span><span class="p">(</span><span class="n">y_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">metric</span>

    <span class="k">def</span> <span class="nf">split_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">y</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">set_train_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to set mode of model in _train_loop&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_valid_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to set mode of model in _train_loop&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to change requires_grad to False for layers</span>

<span class="sd">        Args:</span>
<span class="sd">            layers (list[str]): list of layers to freeze, freeze all if None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;.&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span>
            <span class="p">]</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">unfreeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to change requires_grad to True for layers</span>

<span class="sd">        Args:</span>
<span class="sd">            layers (list[str]): list of layers to unfreeze, unfreeze all if None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;.&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span>
            <span class="p">]</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method for TSEngine to predict in inference_mode&quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
            <span class="n">y_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">y_logits</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">metric_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">valid_dataloader</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initializes the SSTLearner instance</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model</code></td>
          <td>
                <code><span title="nn.Module">Module</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>torch model</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>loss_fn</code></td>
          <td>
                <code><span title="typing.Callable">Callable</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>loss function</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>metric_fn</code></td>
          <td>
                <code><span title="typing.Callable">Callable</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>metric function, Default to None</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>train_dataloader</code></td>
          <td>
                <code>DataLoader</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>train dataloader, Default to None, can be set using set_loaders()</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>valid_dataloader</code></td>
          <td>
                <code>DataLoader</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>valid dataloader, Default to None, can be set using set_loaders()</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">metric_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">valid_dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes the SSTLearner instance</span>

<span class="sd">    Args:</span>
<span class="sd">        model (nn.Module): torch model</span>
<span class="sd">        loss_fn (Callable): loss function</span>
<span class="sd">        metric_fn (Callable): metric function, Default to None</span>
<span class="sd">        train_dataloader (DataLoader): train dataloader, Default to None, can be set using set_loaders()</span>
<span class="sd">        valid_dataloader (DataLoader): valid dataloader, Default to None, can be set using set_loaders()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span> <span class="o">=</span> <span class="n">metric_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">train_dataloader</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">valid_dataloader</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="n">Handles</span><span class="p">:</span>
        <span class="n">handle</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.freeze" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">freeze</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to change requires_grad to False for layers</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>layers</code></td>
          <td>
                <code>list[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>list of layers to freeze, freeze all if None</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to change requires_grad to False for layers</span>

<span class="sd">    Args:</span>
<span class="sd">        layers (list[str]): list of layers to freeze, freeze all if None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;.&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span>
        <span class="p">]</span>

    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.predict" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method for TSEngine to predict in inference_mode</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method for TSEngine to predict in inference_mode&quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
        <span class="n">y_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">y_logits</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.set_train_mode" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_train_mode</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to set mode of model in _train_loop</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_train_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to set mode of model in _train_loop&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.set_valid_mode" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_valid_mode</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to set mode of model in _train_loop</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_valid_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to set mode of model in _train_loop&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.train" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method for SSTLearner to run train and valid loops</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>epochs</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>num of epochs to run</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method for SSTLearner to run train and valid loops</span>

<span class="sd">    Args:</span>
<span class="sd">        epochs (int): num of epochs to run</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_loop</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_dataloader</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_valid_loop</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.train_step" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">train_step</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Standard train step</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Standard train step&quot;&quot;&quot;</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_batch</span><span class="p">()</span>
    <span class="n">y_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span><span class="p">(</span><span class="n">y_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">metric</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.unfreeze" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">unfreeze</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to change requires_grad to True for layers</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>layers</code></td>
          <td>
                <code>list[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>list of layers to unfreeze, unfreeze all if None</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">unfreeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to change requires_grad to True for layers</span>

<span class="sd">    Args:</span>
<span class="sd">        layers (list[str]): list of layers to unfreeze, unfreeze all if None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;.&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span>
        <span class="p">]</span>

    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.main_handler.SSTLearner.valid_step" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">valid_step</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Standard valid step</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\main_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">valid_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Standard valid step&quot;&quot;&quot;</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_batch</span><span class="p">()</span>
    <span class="n">y_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span><span class="p">(</span><span class="n">y_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fn</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">metric</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.callback_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.callback_handler.Callback" class="doc doc-heading">
          <code>Callback</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Base Callback class template for creating callbacks</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\callback_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Callback</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base Callback class template for creating callbacks&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_valid_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_valid_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_loss_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_loss_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_valid_loss_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">on_valid_loss_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.checkpoint_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.checkpoint_handler.CheckPointHandler" class="doc doc-heading">
          <code>CheckPointHandler</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Class for handling checkpoint saving and loading</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\checkpoint_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CheckPointHandler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for handling checkpoint saving and loading&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to save model checkpoint</span>

<span class="sd">        Args: </span>
<span class="sd">            filename (str): filename in pt/pth of model, e.g. &#39;model_path/model.pt&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">,</span>
            <span class="s2">&quot;model_state_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;results&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to load model checkpoint</span>

<span class="sd">        Args: </span>
<span class="sd">            filename (str): file path of checkpoint to load in pt/pth format, e.g. &#39;model_path/model.pt&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;model_state_dict&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;results&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.checkpoint_handler.CheckPointHandler.load_checkpoint" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to load model checkpoint</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>filename</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>file path of checkpoint to load in pt/pth format, e.g. 'model_path/model.pt'</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\checkpoint_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to load model checkpoint</span>

<span class="sd">    Args: </span>
<span class="sd">        filename (str): file path of checkpoint to load in pt/pth format, e.g. &#39;model_path/model.pt&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;model_state_dict&quot;</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;results&quot;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.checkpoint_handler.CheckPointHandler.save_checkpoint" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to save model checkpoint</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>filename</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>filename in pt/pth of model, e.g. 'model_path/model.pt'</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\checkpoint_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to save model checkpoint</span>

<span class="sd">    Args: </span>
<span class="sd">        filename (str): filename in pt/pth of model, e.g. &#39;model_path/model.pt&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">,</span>
        <span class="s2">&quot;model_state_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s2">&quot;results&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.device_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.device_handler.DeviceHandler" class="doc doc-heading">
          <code>DeviceHandler</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Class for handling device management</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\device_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DeviceHandler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for handling device management&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">to_device</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>



<div class="doc doc-object doc-function">



<h2 id="src.sstorch.learner.device_handler.to_device" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">to_device</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Method to put variable X to gpu if available</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>X</code></td>
          <td>
                <code><span title="typing.Any">Any</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>list/tuple/dict that contains tensors</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>device</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>GPU - 'cuda', CPU - 'cpu'</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\device_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to put variable X to gpu if available</span>

<span class="sd">    Args:</span>
<span class="sd">        X (Any):    list/tuple/dict that contains tensors</span>
<span class="sd">        device (str):   GPU - &#39;cuda&#39;, CPU - &#39;cpu&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">to_device</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">to_device</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.gradient_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.gradient_handler.GradientHandler" class="doc doc-heading">
          <code>GradientHandler</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Class for handling gradient clipping</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\gradient_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">GradientHandler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for handling gradient clipping&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">GradientClipping</span> <span class="o">=</span> <span class="n">GradientClipping</span>

    <span class="k">def</span> <span class="nf">set_clip_grad_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clip_value</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to perform Value Clipping</span>

<span class="sd">        Clips gradients element-wise so that they stay inside the [-clip_value, +clip_value]</span>
<span class="sd">        Reference: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_value_.html</span>
<span class="sd">        Executed in GradientClipping Callback</span>

<span class="sd">        Args:</span>
<span class="sd">          clip_value (float): max and min gradient value</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_value_</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip_value</span><span class="o">=</span><span class="n">clip_value</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_clip_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to perform Norm Clipping</span>

<span class="sd">        Norm clipping computes the norm for all gradeints together if they were concatedated into a single vector</span>
<span class="sd">        if the norm exceeds teh clipping value, teh gradients are scaled down to match the desired norm</span>
<span class="sd">        Reference: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html</span>
<span class="sd">        Executed in GradientClipping Callback</span>

<span class="sd">        Args:</span>
<span class="sd">          max_norm (float): max norm of the gradients</span>
<span class="sd">          norm_type (float): type of the used p-norm. Can be &#39;inf&#39; for infinity norm</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="n">max_norm</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_clip_backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clip_value</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to set clip gradient on the fly using backward hook (register_hook)</span>
<span class="sd">        clamp all grad using torch.clamp between [-clip_value, +clip_value]</span>

<span class="sd">        Args:</span>
<span class="sd">          clip_value (float): max and min gradient value</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>

                <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">grad</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="n">clip_value</span><span class="p">,</span> <span class="n">clip_value</span><span class="p">)</span>

                <span class="n">handle</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">remove_clip</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to remove gradient clipping in backward hook&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="p">:</span>
                <span class="n">handle</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.gradient_handler.GradientHandler.remove_clip" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">remove_clip</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to remove gradient clipping in backward hook</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\gradient_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">remove_clip</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to remove gradient clipping in backward hook&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="p">:</span>
            <span class="n">handle</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.gradient_handler.GradientHandler.set_clip_backprop" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_clip_backprop</span><span class="p">(</span><span class="n">clip_value</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to set clip gradient on the fly using backward hook (register_hook)
clamp all grad using torch.clamp between [-clip_value, +clip_value]</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>clip_value</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>max and min gradient value</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\gradient_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_clip_backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clip_value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to set clip gradient on the fly using backward hook (register_hook)</span>
<span class="sd">    clamp all grad using torch.clamp between [-clip_value, +clip_value]</span>

<span class="sd">    Args:</span>
<span class="sd">      clip_value (float): max and min gradient value</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">grad</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="n">clip_value</span><span class="p">,</span> <span class="n">clip_value</span><span class="p">)</span>

            <span class="n">handle</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.gradient_handler.GradientHandler.set_clip_grad_norm" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_clip_grad_norm</span><span class="p">(</span><span class="n">max_norm</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to perform Norm Clipping</p>
<p>Norm clipping computes the norm for all gradeints together if they were concatedated into a single vector
if the norm exceeds teh clipping value, teh gradients are scaled down to match the desired norm
Reference: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html
Executed in GradientClipping Callback</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>max_norm</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>max norm of the gradients</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>norm_type</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>type of the used p-norm. Can be 'inf' for infinity norm</p>
            </div>
          </td>
          <td>
                <code>2</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\gradient_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_clip_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to perform Norm Clipping</span>

<span class="sd">    Norm clipping computes the norm for all gradeints together if they were concatedated into a single vector</span>
<span class="sd">    if the norm exceeds teh clipping value, teh gradients are scaled down to match the desired norm</span>
<span class="sd">    Reference: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html</span>
<span class="sd">    Executed in GradientClipping Callback</span>

<span class="sd">    Args:</span>
<span class="sd">      max_norm (float): max norm of the gradients</span>
<span class="sd">      norm_type (float): type of the used p-norm. Can be &#39;inf&#39; for infinity norm</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="n">max_norm</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.gradient_handler.GradientHandler.set_clip_grad_value" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_clip_grad_value</span><span class="p">(</span><span class="n">clip_value</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to perform Value Clipping</p>
<p>Clips gradients element-wise so that they stay inside the [-clip_value, +clip_value]
Reference: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_value_.html
Executed in GradientClipping Callback</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>clip_value</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>max and min gradient value</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\gradient_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_clip_grad_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clip_value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to perform Value Clipping</span>

<span class="sd">    Clips gradients element-wise so that they stay inside the [-clip_value, +clip_value]</span>
<span class="sd">    Reference: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_value_.html</span>
<span class="sd">    Executed in GradientClipping Callback</span>

<span class="sd">    Args:</span>
<span class="sd">      clip_value (float): max and min gradient value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_value_</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip_value</span><span class="o">=</span><span class="n">clip_value</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.hook_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.hook_handler.HookHandler" class="doc doc-heading">
          <code>HookHandler</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Class for handling forward and backward hook</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\hook_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">HookHandler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for handling forward and backward hook&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modules</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">layer</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="mi">1</span><span class="p">:]}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forward_hook_handles</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backward_hook_handles</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">attach_forward_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers_to_hook</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">hook_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to attach custom forward hooks</span>

<span class="sd">        Args:</span>
<span class="sd">          layers_to_hook (list):    list of layers to hook</span>
<span class="sd">          hook_fn (Callable):   custom hook_fn in during forward pass</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">layers_to_hook</span><span class="p">:</span>
                <span class="n">handle</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">hook_fn</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">forward_hook_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">attach_backward_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers_to_hook</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">hook_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to attach custom backward hooks</span>

<span class="sd">        Args:</span>
<span class="sd">          layers_to_hook (list):    list of layers to hook</span>
<span class="sd">          hook_fn (Callable):   custom hook_fn in during backward pass</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">layers_to_hook</span><span class="p">:</span>
                <span class="n">handle</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">register_full_backward_hook</span><span class="p">(</span><span class="n">hook_fn</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">backward_hook_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">remove_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to remove both custom forward and backward hook&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_hook_handles</span><span class="p">:</span>
            <span class="n">handle</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forward_hook_handles</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">backward_hook_handles</span><span class="p">:</span>
            <span class="n">handle</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backward_hook_handles</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.hook_handler.HookHandler.attach_backward_hooks" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">attach_backward_hooks</span><span class="p">(</span><span class="n">layers_to_hook</span><span class="p">,</span> <span class="n">hook_fn</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to attach custom backward hooks</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>layers_to_hook</code></td>
          <td>
                <code>list</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>list of layers to hook</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>hook_fn</code></td>
          <td>
                <code><span title="typing.Callable">Callable</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>custom hook_fn in during backward pass</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\hook_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">attach_backward_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers_to_hook</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">hook_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to attach custom backward hooks</span>

<span class="sd">    Args:</span>
<span class="sd">      layers_to_hook (list):    list of layers to hook</span>
<span class="sd">      hook_fn (Callable):   custom hook_fn in during backward pass</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">layers_to_hook</span><span class="p">:</span>
            <span class="n">handle</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">register_full_backward_hook</span><span class="p">(</span><span class="n">hook_fn</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">backward_hook_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.hook_handler.HookHandler.attach_forward_hooks" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">attach_forward_hooks</span><span class="p">(</span><span class="n">layers_to_hook</span><span class="p">,</span> <span class="n">hook_fn</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to attach custom forward hooks</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>layers_to_hook</code></td>
          <td>
                <code>list</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>list of layers to hook</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>hook_fn</code></td>
          <td>
                <code><span title="typing.Callable">Callable</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>custom hook_fn in during forward pass</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\hook_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">attach_forward_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers_to_hook</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">hook_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to attach custom forward hooks</span>

<span class="sd">    Args:</span>
<span class="sd">      layers_to_hook (list):    list of layers to hook</span>
<span class="sd">      hook_fn (Callable):   custom hook_fn in during forward pass</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">layers_to_hook</span><span class="p">:</span>
            <span class="n">handle</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">hook_fn</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">forward_hook_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.hook_handler.HookHandler.remove_hooks" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">remove_hooks</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to remove both custom forward and backward hook</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\hook_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">remove_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to remove both custom forward and backward hook&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_hook_handles</span><span class="p">:</span>
        <span class="n">handle</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">forward_hook_handles</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">backward_hook_handles</span><span class="p">:</span>
        <span class="n">handle</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">backward_hook_handles</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.optimizer_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.optimizer_handler.OptimizerHandler" class="doc doc-heading">
          <code>OptimizerHandler</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Class for handling Learning Rates</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\optimizer_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">OptimizerHandler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for handling Learning Rates&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">configure_optimizer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_batch_lr_scheduler</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LearningRateScheduler</span> <span class="o">=</span> <span class="n">LearningRateScheduler</span>

    <span class="k">def</span> <span class="nf">configure_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to configure optimizer on initialisation</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
            <span class="s2">&quot;Need to define configure_optimizer() to setup optimizer for training&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">defaults</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to set optimizer</span>

<span class="sd">        Args:</span>
<span class="sd">            optimizer (torch.optim.Optimizer):  optimizer to be set</span>
<span class="sd">            defaults (dict[str, float]):    defaults of optimizer in</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">**</span><span class="n">defaults</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_lr_scheduler</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">is_batch_lr_scheduler</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to set LR scheduler</span>

<span class="sd">        Args:</span>
<span class="sd">            scheduler (torch.optim.scheduler): Learning Rate Scheduler</span>
<span class="sd">                Reference: https://pytorch.org/docs/stable/optim.html#module-torch.optim.lr_scheduler</span>

<span class="sd">            is_batch_lr_scheduler (bool): True for batch scheduler, False for epoch scheduler</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">scheduler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_batch_lr_scheduler</span> <span class="o">=</span> <span class="n">is_batch_lr_scheduler</span>

    <span class="k">def</span> <span class="nf">set_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to set learning rate</span>

<span class="sd">        Args: lr [float]: learning rate</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">g</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

    <span class="k">def</span> <span class="nf">lr_range_test</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">end_lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">start_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">step_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;exp&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
        <span class="n">show_graph</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to perform LR Range Test</span>

<span class="sd">        Reference: Leslie N. Smith &#39;Cyclical Learning Rates for Training Neual Networks</span>

<span class="sd">        Args:</span>
<span class="sd">          end_lr (float):   upper boundary for the LR Range test</span>
<span class="sd">          start_lr (float): lower boundary for the LR Range test, Defaults to current optimizer LR</span>
<span class="sd">          num_iter (int):   number of interations to move from start_lr to end_lr</span>
<span class="sd">          step_mode (str):  show LR range test linear or log scale, Defaults to &#39;exp&#39;</span>
<span class="sd">          alpha (float):    alpha term for smoothed loss (smooth_loss = alpha * loss + (1-alpha) * prev_loss)</span>
<span class="sd">          show_graph (bool):    to show LR Range Test result in plot</span>

<span class="sd">        Return:</span>
<span class="sd">          max_grad_lr (float):  LR with maximum loss gradient (steepest)</span>
<span class="sd">          min_loss_lr (float):  LR with minium loss (minimum)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">previous_states</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span>
            <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">start_lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_lr</span><span class="p">(</span><span class="n">start_lr</span><span class="p">)</span>
        <span class="n">start_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s2">&quot;param_groups&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
        <span class="n">lr_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_lr_fn</span><span class="p">(</span><span class="n">start_lr</span><span class="p">,</span> <span class="n">end_lr</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">)</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="o">=</span><span class="n">lr_fn</span><span class="p">)</span>
        <span class="n">tracking</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="p">[]}</span>
        <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_iter</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">iteration</span> <span class="o">&lt;</span> <span class="n">num_iter</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">iteration</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">prev_loss</span> <span class="o">=</span> <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">smoothed_loss</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">prev_loss</span>
                    <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smoothed_loss</span><span class="p">)</span>
                <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">iteration</span> <span class="o">==</span> <span class="n">num_iter</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">max_grad_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]))</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
        <span class="n">min_loss_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
        <span class="n">max_grad_lr</span> <span class="o">=</span> <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">][</span><span class="n">max_grad_idx</span><span class="p">]</span>
        <span class="n">min_loss_lr</span> <span class="o">=</span> <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">][</span><span class="n">min_loss_idx</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">previous_states</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">previous_states</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">show_graph</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max Gradient: </span><span class="si">{</span><span class="n">max_grad_lr</span><span class="si">:</span><span class="s2">.2E</span><span class="si">}</span><span class="s2"> | Lowest Loss: </span><span class="si">{</span><span class="n">min_loss_lr</span><span class="si">:</span><span class="s2">.2E</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span> <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">][</span><span class="n">max_grad_idx</span><span class="p">],</span>
                <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="n">max_grad_idx</span><span class="p">],</span>
                <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Max Gradient&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">][</span><span class="n">min_loss_idx</span><span class="p">],</span>
                <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="n">min_loss_idx</span><span class="p">],</span>
                <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Min Loss&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">step_mode</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">max_grad_lr</span><span class="p">,</span> <span class="n">min_loss_lr</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">make_lr_fn</span><span class="p">(</span>
        <span class="n">start_lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">end_lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">step_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;exp&quot;</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to generate learning rate function (internal only)&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">step_mode</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">end_lr</span> <span class="o">/</span> <span class="n">start_lr</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_iter</span>

            <span class="k">def</span> <span class="nf">lr_fn</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
                <span class="k">return</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">iteration</span> <span class="o">*</span> <span class="n">factor</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">end_lr</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">start_lr</span><span class="p">))</span> <span class="o">/</span> <span class="n">num_iter</span>

            <span class="k">def</span> <span class="nf">lr_fn</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span> <span class="o">**</span> <span class="n">iteration</span>

        <span class="k">return</span> <span class="n">lr_fn</span>

    <span class="k">def</span> <span class="nf">fit_one_cycle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to perform fit one cycle polcy</span>

<span class="sd">        Sets the learning rate of each parameter group according to the 1cycle learning rate policy.</span>
<span class="sd">        The 1cycle policy anneals the learning rate from an initial learning rate to some maximum learning rate</span>
<span class="sd">        and then from that maximum learning rate to some minimum learning rate</span>

<span class="sd">        Args:</span>
<span class="sd">          epochs (int): The number of epochs to train for</span>
<span class="sd">          max_lr (float):   Upper learning rate boundaries in the cycle for each parameter group, Default: None</span>
<span class="sd">          min_lr (float):   Lower learning rate boundaries in the cycle for each parameter group, Default: None</span>

<span class="sd">          If max_lr and min_lr is not specified,</span>
<span class="sd">          lr_range_test will be performed</span>
<span class="sd">          with max_lr set to min_loss_lr and min_lr set to max_grad_lr</span>

<span class="sd">        Reference: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html</span>
<span class="sd">        Reference: https://arxiv.org/abs/1708.07120</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">max_lr</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">min_lr</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_grad_lr</span><span class="p">,</span> <span class="n">min_loss_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_range_test</span><span class="p">(</span>
                <span class="n">end_lr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">step_mode</span><span class="o">=</span><span class="s2">&quot;exp&quot;</span><span class="p">,</span> <span class="n">show_graph</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">max_lr</span> <span class="o">=</span> <span class="n">max_lr</span> <span class="k">if</span> <span class="n">max_lr</span> <span class="k">else</span> <span class="n">min_loss_lr</span>
            <span class="n">min_lr</span> <span class="o">=</span> <span class="n">min_lr</span> <span class="k">if</span> <span class="n">min_lr</span> <span class="k">else</span> <span class="n">max_grad_lr</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max LR: </span><span class="si">{</span><span class="n">max_lr</span><span class="si">:</span><span class="s2">.1E</span><span class="si">}</span><span class="s2"> | Min LR: </span><span class="si">{</span><span class="n">min_lr</span><span class="si">:</span><span class="s2">.1E</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">pervious_optimizer</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_lr</span><span class="p">(</span><span class="n">min_lr</span><span class="p">)</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">max_lr</span><span class="o">=</span><span class="n">max_lr</span><span class="p">,</span>
            <span class="n">total_steps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">epochs</span> <span class="o">*</span> <span class="mf">1.05</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_lr_scheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span> <span class="n">is_batch_lr_scheduler</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_lr_scheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">pervious_optimizer</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.optimizer_handler.OptimizerHandler.configure_optimizer" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">configure_optimizer</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to configure optimizer on initialisation</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\optimizer_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">configure_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to configure optimizer on initialisation</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
        <span class="s2">&quot;Need to define configure_optimizer() to setup optimizer for training&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.optimizer_handler.OptimizerHandler.fit_one_cycle" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to perform fit one cycle polcy</p>
<p>Sets the learning rate of each parameter group according to the 1cycle learning rate policy.
The 1cycle policy anneals the learning rate from an initial learning rate to some maximum learning rate
and then from that maximum learning rate to some minimum learning rate</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>epochs</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The number of epochs to train for</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>max_lr</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Upper learning rate boundaries in the cycle for each parameter group, Default: None</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>min_lr</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Lower learning rate boundaries in the cycle for each parameter group, Default: None</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>
      <p>Reference: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html
Reference: https://arxiv.org/abs/1708.07120</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\optimizer_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit_one_cycle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to perform fit one cycle polcy</span>

<span class="sd">    Sets the learning rate of each parameter group according to the 1cycle learning rate policy.</span>
<span class="sd">    The 1cycle policy anneals the learning rate from an initial learning rate to some maximum learning rate</span>
<span class="sd">    and then from that maximum learning rate to some minimum learning rate</span>

<span class="sd">    Args:</span>
<span class="sd">      epochs (int): The number of epochs to train for</span>
<span class="sd">      max_lr (float):   Upper learning rate boundaries in the cycle for each parameter group, Default: None</span>
<span class="sd">      min_lr (float):   Lower learning rate boundaries in the cycle for each parameter group, Default: None</span>

<span class="sd">      If max_lr and min_lr is not specified,</span>
<span class="sd">      lr_range_test will be performed</span>
<span class="sd">      with max_lr set to min_loss_lr and min_lr set to max_grad_lr</span>

<span class="sd">    Reference: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html</span>
<span class="sd">    Reference: https://arxiv.org/abs/1708.07120</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">max_lr</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">min_lr</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_grad_lr</span><span class="p">,</span> <span class="n">min_loss_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_range_test</span><span class="p">(</span>
            <span class="n">end_lr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">step_mode</span><span class="o">=</span><span class="s2">&quot;exp&quot;</span><span class="p">,</span> <span class="n">show_graph</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">max_lr</span> <span class="o">=</span> <span class="n">max_lr</span> <span class="k">if</span> <span class="n">max_lr</span> <span class="k">else</span> <span class="n">min_loss_lr</span>
        <span class="n">min_lr</span> <span class="o">=</span> <span class="n">min_lr</span> <span class="k">if</span> <span class="n">min_lr</span> <span class="k">else</span> <span class="n">max_grad_lr</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max LR: </span><span class="si">{</span><span class="n">max_lr</span><span class="si">:</span><span class="s2">.1E</span><span class="si">}</span><span class="s2"> | Min LR: </span><span class="si">{</span><span class="n">min_lr</span><span class="si">:</span><span class="s2">.1E</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">pervious_optimizer</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">set_lr</span><span class="p">(</span><span class="n">min_lr</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
        <span class="n">max_lr</span><span class="o">=</span><span class="n">max_lr</span><span class="p">,</span>
        <span class="n">total_steps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">epochs</span> <span class="o">*</span> <span class="mf">1.05</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">set_lr_scheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span> <span class="n">is_batch_lr_scheduler</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">set_lr_scheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">pervious_optimizer</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.optimizer_handler.OptimizerHandler.lr_range_test" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">lr_range_test</span><span class="p">(</span><span class="n">end_lr</span><span class="p">,</span> <span class="n">start_lr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">step_mode</span><span class="o">=</span><span class="s1">&#39;exp&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">show_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to perform LR Range Test</p>
<p>Reference: Leslie N. Smith 'Cyclical Learning Rates for Training Neual Networks</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>end_lr</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>upper boundary for the LR Range test</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>start_lr</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>lower boundary for the LR Range test, Defaults to current optimizer LR</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>num_iter</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>number of interations to move from start_lr to end_lr</p>
            </div>
          </td>
          <td>
                <code>100</code>
          </td>
        </tr>
        <tr>
          <td><code>step_mode</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>show LR range test linear or log scale, Defaults to 'exp'</p>
            </div>
          </td>
          <td>
                <code>&#39;exp&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>alpha</code></td>
          <td>
                <code>float</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>alpha term for smoothed loss (smooth_loss = alpha * loss + (1-alpha) * prev_loss)</p>
            </div>
          </td>
          <td>
                <code>0.05</code>
          </td>
        </tr>
        <tr>
          <td><code>show_graph</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>to show LR Range Test result in plot</p>
            </div>
          </td>
          <td>
                <code>True</code>
          </td>
        </tr>
    </tbody>
  </table>

<details class="return" open>
  <summary>Return</summary>
  <p>max_grad_lr (float):  LR with maximum loss gradient (steepest)
min_loss_lr (float):  LR with minium loss (minimum)</p>
</details>
          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\optimizer_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">lr_range_test</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">end_lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">start_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">step_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;exp&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
    <span class="n">show_graph</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to perform LR Range Test</span>

<span class="sd">    Reference: Leslie N. Smith &#39;Cyclical Learning Rates for Training Neual Networks</span>

<span class="sd">    Args:</span>
<span class="sd">      end_lr (float):   upper boundary for the LR Range test</span>
<span class="sd">      start_lr (float): lower boundary for the LR Range test, Defaults to current optimizer LR</span>
<span class="sd">      num_iter (int):   number of interations to move from start_lr to end_lr</span>
<span class="sd">      step_mode (str):  show LR range test linear or log scale, Defaults to &#39;exp&#39;</span>
<span class="sd">      alpha (float):    alpha term for smoothed loss (smooth_loss = alpha * loss + (1-alpha) * prev_loss)</span>
<span class="sd">      show_graph (bool):    to show LR Range Test result in plot</span>

<span class="sd">    Return:</span>
<span class="sd">      max_grad_lr (float):  LR with maximum loss gradient (steepest)</span>
<span class="sd">      min_loss_lr (float):  LR with minium loss (minimum)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">previous_states</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span>
        <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">start_lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_lr</span><span class="p">(</span><span class="n">start_lr</span><span class="p">)</span>
    <span class="n">start_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s2">&quot;param_groups&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
    <span class="n">lr_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_lr_fn</span><span class="p">(</span><span class="n">start_lr</span><span class="p">,</span> <span class="n">end_lr</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="o">=</span><span class="n">lr_fn</span><span class="p">)</span>
    <span class="n">tracking</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_iter</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">iteration</span> <span class="o">&lt;</span> <span class="n">num_iter</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">iteration</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prev_loss</span> <span class="o">=</span> <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">smoothed_loss</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">prev_loss</span>
                <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smoothed_loss</span><span class="p">)</span>
            <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">iteration</span> <span class="o">==</span> <span class="n">num_iter</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">max_grad_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]))</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
    <span class="n">min_loss_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
    <span class="n">max_grad_lr</span> <span class="o">=</span> <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">][</span><span class="n">max_grad_idx</span><span class="p">]</span>
    <span class="n">min_loss_lr</span> <span class="o">=</span> <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">][</span><span class="n">min_loss_idx</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">previous_states</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">previous_states</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">show_graph</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max Gradient: </span><span class="si">{</span><span class="n">max_grad_lr</span><span class="si">:</span><span class="s2">.2E</span><span class="si">}</span><span class="s2"> | Lowest Loss: </span><span class="si">{</span><span class="n">min_loss_lr</span><span class="si">:</span><span class="s2">.2E</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span> <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">][</span><span class="n">max_grad_idx</span><span class="p">],</span>
            <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="n">max_grad_idx</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Max Gradient&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">][</span><span class="n">min_loss_idx</span><span class="p">],</span>
            <span class="n">tracking</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="n">min_loss_idx</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Min Loss&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">step_mode</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">max_grad_lr</span><span class="p">,</span> <span class="n">min_loss_lr</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.optimizer_handler.OptimizerHandler.make_lr_fn" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">make_lr_fn</span><span class="p">(</span><span class="n">start_lr</span><span class="p">,</span> <span class="n">end_lr</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">,</span> <span class="n">step_mode</span><span class="o">=</span><span class="s1">&#39;exp&#39;</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to generate learning rate function (internal only)</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\optimizer_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">make_lr_fn</span><span class="p">(</span>
    <span class="n">start_lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">end_lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">step_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;exp&quot;</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to generate learning rate function (internal only)&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">step_mode</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
        <span class="n">factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">end_lr</span> <span class="o">/</span> <span class="n">start_lr</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_iter</span>

        <span class="k">def</span> <span class="nf">lr_fn</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">iteration</span> <span class="o">*</span> <span class="n">factor</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">end_lr</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">start_lr</span><span class="p">))</span> <span class="o">/</span> <span class="n">num_iter</span>

        <span class="k">def</span> <span class="nf">lr_fn</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span> <span class="o">**</span> <span class="n">iteration</span>

    <span class="k">return</span> <span class="n">lr_fn</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.optimizer_handler.OptimizerHandler.set_lr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_lr</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to set learning rate</p>
<p>Args: lr [float]: learning rate</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\optimizer_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to set learning rate</span>

<span class="sd">    Args: lr [float]: learning rate</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">g</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.optimizer_handler.OptimizerHandler.set_lr_scheduler" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_lr_scheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="p">,</span> <span class="n">is_batch_lr_scheduler</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to set LR scheduler</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>scheduler</code></td>
          <td>
                <code><span title="torch.optim.scheduler">scheduler</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Learning Rate Scheduler
Reference: https://pytorch.org/docs/stable/optim.html#module-torch.optim.lr_scheduler</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>is_batch_lr_scheduler</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>True for batch scheduler, False for epoch scheduler</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\optimizer_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_lr_scheduler</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">is_batch_lr_scheduler</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to set LR scheduler</span>

<span class="sd">    Args:</span>
<span class="sd">        scheduler (torch.optim.scheduler): Learning Rate Scheduler</span>
<span class="sd">            Reference: https://pytorch.org/docs/stable/optim.html#module-torch.optim.lr_scheduler</span>

<span class="sd">        is_batch_lr_scheduler (bool): True for batch scheduler, False for epoch scheduler</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">scheduler</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">is_batch_lr_scheduler</span> <span class="o">=</span> <span class="n">is_batch_lr_scheduler</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.optimizer_handler.OptimizerHandler.set_optimizer" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to set optimizer</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>optimizer</code></td>
          <td>
                <code><span title="torch.optim.Optimizer">Optimizer</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>optimizer to be set</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>defaults</code></td>
          <td>
                <code>dict[str, float]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>defaults of optimizer in</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\optimizer_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_optimizer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">defaults</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to set optimizer</span>

<span class="sd">    Args:</span>
<span class="sd">        optimizer (torch.optim.Optimizer):  optimizer to be set</span>
<span class="sd">        defaults (dict[str, float]):    defaults of optimizer in</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">**</span><span class="n">defaults</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.result_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.result_handler.ResultHandler" class="doc doc-heading">
          <code>ResultHandler</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Class for handling Printing and Saving Results</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\result_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ResultHandler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for handling Printing and Saving Results&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metric</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_metric</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PrintResults</span> <span class="o">=</span> <span class="n">PrintResults</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">SaveResults</span> <span class="o">=</span> <span class="n">SaveResults</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_keys</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_num</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;train_metric&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;valid_loss&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;valid_metric&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">plot_loss_curve</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to plot loss curve&quot;&quot;&quot;</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train Loss&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;valid_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Valid Loss&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.result_handler.ResultHandler.plot_loss_curve" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">plot_loss_curve</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to plot loss curve</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\result_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot_loss_curve</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to plot loss curve&quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;valid_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Valid Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.tensorboard_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.tensorboard_handler.TBHandler" class="doc doc-heading">
          <code>TBHandler</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Class for handling TensorBoard</p>

            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\tensorboard_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TBHandler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for handling TensorBoard&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TBWriter</span> <span class="o">=</span> <span class="n">TBWriter</span>

    <span class="k">def</span> <span class="nf">set_tensorboard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">folder</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;runs&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to set TSEngine tensorboard</span>

<span class="sd">        Args:</span>
<span class="sd">          name (str):   name of project</span>
<span class="sd">          folder (str): name of folder to run tensorboard logs, Defaults to &#39;runs&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">suffix</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to add graph for TensorBoard&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">))</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.tensorboard_handler.TBHandler.add_graph" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">add_graph</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to add graph for TensorBoard</p>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\tensorboard_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to add graph for TensorBoard&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">))</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.tensorboard_handler.TBHandler.set_tensorboard" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_tensorboard</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;runs&#39;</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to set TSEngine tensorboard</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>name</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>name of project</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>folder</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>name of folder to run tensorboard logs, Defaults to 'runs'</p>
            </div>
          </td>
          <td>
                <code>&#39;runs&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\tensorboard_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_tensorboard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">folder</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;runs&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to set TSEngine tensorboard</span>

<span class="sd">    Args:</span>
<span class="sd">      name (str):   name of project</span>
<span class="sd">      folder (str): name of folder to run tensorboard logs, Defaults to &#39;runs&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">suffix</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.torchinfo_handler"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.sstorch.learner.torchinfo_handler.TorchInfoHandler" class="doc doc-heading">
          <code>TorchInfoHandler</code>


</h2>


  <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>src\sstorch\learner\torchinfo_handler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TorchInfoHandler</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">model_info</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">col_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="s2">&quot;output_size&quot;</span><span class="p">,</span> <span class="s2">&quot;num_params&quot;</span><span class="p">,</span> <span class="s2">&quot;trainable&quot;</span><span class="p">],</span>
        <span class="n">col_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">row_settings</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;var_names&quot;</span><span class="p">],</span>
        <span class="n">input_data</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to utilise torchinfo to show model summary</span>

<span class="sd">        Reference: https://github.com/TylerYep/torchinfo</span>

<span class="sd">        Args:</span>
<span class="sd">            col_names (Iterable[str]):  Specify which columns to show in the output</span>
<span class="sd">                Currently supported: (&quot;input_size&quot;,&quot;output_size&quot;,&quot;num_params&quot;,&quot;params_percent&quot;,&quot;kernel_size&quot;,&quot;mult_adds&quot;,&quot;trainable&quot;)</span>
<span class="sd">                Default: [&quot;input_size&quot;, &quot;output_size&quot;, &quot;num_params&quot;, &quot;trainable&quot;]</span>

<span class="sd">            col_width (int):    Width of each column. Default: 20</span>

<span class="sd">            row_settings (Iterable[str]):   Specify which features to show in a row. </span>
<span class="sd">                Currently supported: (&quot;ascii_only&quot;, &quot;depth&quot;, &quot;var_names&quot;)</span>
<span class="sd">                Default: (&quot;var_names&quot;)</span>

<span class="sd">            input_data (Sequence of Tensors):   Arguments for the model&#39;s forward pass (dtypes inferred).</span>
<span class="sd">                If the forward() function takes several parameters, pass in a list of</span>
<span class="sd">                args or a dict of kwargs (if your forward() function takes in a dict</span>
<span class="sd">                as its only argument, wrap it in a list).</span>
<span class="sd">                Default: None</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">input_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">input_data</span><span class="p">,</span> <span class="o">*</span><span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">input_data</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="n">torchinfo</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">col_names</span><span class="o">=</span><span class="n">col_names</span><span class="p">,</span>
                <span class="n">col_width</span><span class="o">=</span><span class="n">col_width</span><span class="p">,</span>
                <span class="n">row_settings</span><span class="o">=</span><span class="n">row_settings</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="src.sstorch.learner.torchinfo_handler.TorchInfoHandler.model_info" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">model_info</span><span class="p">(</span><span class="n">col_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_size&#39;</span><span class="p">,</span> <span class="s1">&#39;output_size&#39;</span><span class="p">,</span> <span class="s1">&#39;num_params&#39;</span><span class="p">,</span> <span class="s1">&#39;trainable&#39;</span><span class="p">],</span> <span class="n">col_width</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">row_settings</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;var_names&#39;</span><span class="p">],</span> <span class="n">input_data</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method to utilise torchinfo to show model summary</p>
<p>Reference: https://github.com/TylerYep/torchinfo</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>col_names</code></td>
          <td>
                <code>Iterable[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Specify which columns to show in the output
Currently supported: ("input_size","output_size","num_params","params_percent","kernel_size","mult_adds","trainable")
Default: ["input_size", "output_size", "num_params", "trainable"]</p>
            </div>
          </td>
          <td>
                <code>[&#39;input_size&#39;, &#39;output_size&#39;, &#39;num_params&#39;, &#39;trainable&#39;]</code>
          </td>
        </tr>
        <tr>
          <td><code>col_width</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Width of each column. Default: 20</p>
            </div>
          </td>
          <td>
                <code>20</code>
          </td>
        </tr>
        <tr>
          <td><code>row_settings</code></td>
          <td>
                <code>Iterable[str]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Specify which features to show in a row. 
Currently supported: ("ascii_only", "depth", "var_names")
Default: ("var_names")</p>
            </div>
          </td>
          <td>
                <code>[&#39;var_names&#39;]</code>
          </td>
        </tr>
        <tr>
          <td><code>input_data</code></td>
          <td>
                <code>Sequence of Tensors</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Arguments for the model's forward pass (dtypes inferred).
If the forward() function takes several parameters, pass in a list of
args or a dict of kwargs (if your forward() function takes in a dict
as its only argument, wrap it in a list).
Default: None</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\torchinfo_handler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">model_info</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">col_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="s2">&quot;output_size&quot;</span><span class="p">,</span> <span class="s2">&quot;num_params&quot;</span><span class="p">,</span> <span class="s2">&quot;trainable&quot;</span><span class="p">],</span>
    <span class="n">col_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">row_settings</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;var_names&quot;</span><span class="p">],</span>
    <span class="n">input_data</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to utilise torchinfo to show model summary</span>

<span class="sd">    Reference: https://github.com/TylerYep/torchinfo</span>

<span class="sd">    Args:</span>
<span class="sd">        col_names (Iterable[str]):  Specify which columns to show in the output</span>
<span class="sd">            Currently supported: (&quot;input_size&quot;,&quot;output_size&quot;,&quot;num_params&quot;,&quot;params_percent&quot;,&quot;kernel_size&quot;,&quot;mult_adds&quot;,&quot;trainable&quot;)</span>
<span class="sd">            Default: [&quot;input_size&quot;, &quot;output_size&quot;, &quot;num_params&quot;, &quot;trainable&quot;]</span>

<span class="sd">        col_width (int):    Width of each column. Default: 20</span>

<span class="sd">        row_settings (Iterable[str]):   Specify which features to show in a row. </span>
<span class="sd">            Currently supported: (&quot;ascii_only&quot;, &quot;depth&quot;, &quot;var_names&quot;)</span>
<span class="sd">            Default: (&quot;var_names&quot;)</span>

<span class="sd">        input_data (Sequence of Tensors):   Arguments for the model&#39;s forward pass (dtypes inferred).</span>
<span class="sd">            If the forward() function takes several parameters, pass in a list of</span>
<span class="sd">            args or a dict of kwargs (if your forward() function takes in a dict</span>
<span class="sd">            as its only argument, wrap it in a list).</span>
<span class="sd">            Default: None</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">input_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">input_data</span><span class="p">,</span> <span class="o">*</span><span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span>
        <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">input_data</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">input_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">torchinfo</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">col_names</span><span class="o">=</span><span class="n">col_names</span><span class="p">,</span>
            <span class="n">col_width</span><span class="o">=</span><span class="n">col_width</span><span class="p">,</span>
            <span class="n">row_settings</span><span class="o">=</span><span class="n">row_settings</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="src.sstorch.learner.utils"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h2 id="src.sstorch.learner.utils.set_seed" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Function to set random seed for torch, numpy and random</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>seed</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>random_seed</p>
            </div>
          </td>
          <td>
                <code>42</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src\sstorch\learner\utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function to set random seed for torch, numpy and random</span>

<span class="sd">    Args: </span>
<span class="sd">        seed (int): random_seed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.bd41221c.min.js"></script>
      
    
  </body>
</html>